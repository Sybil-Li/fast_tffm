[General]
# The number of features stored in the model.
# feature_entry_id = feature_original_id % vocabulary_size
vocabulary_size = 800000

# Number of vocabulary blocks. Each vocabulary block holds
# (vocabulary_size / vocabulary_block_num + 1) entries.
vocabulary_block_num = 10

# The total memory used is vocabulary_size * (factor_num + 1). The "1" is
# used for saving a bias term for each feature entry.
factor_num = 100

# The file path 1) for saving model when training;
# 2) for loading model when predicting.
model_file = ./model

# Data file input format: <label> <fid_0>[:<fval_0>] [<fid_1>[:<fval_1>] ... ]
# If hash_feature_id = True, <fid_k> must be an integer; otherwise, the
# <fid_k> string will be hashed to an int64
hash_feature_id = False

# Log file path for tensorboard visualization. Should be empty!
log_file = ./log

[Train]
batch_size = 50000
init_value_range = 0.01
factor_lambda = 0
bias_lambda = 0
epoch_num = 20
learning_rate = 0.01
adagrad.initial_accumulator = 0.1

# The following parameters are suggested for optimal performance based on
# currently available devices. User may change them for specific tasks/
# system configurations.
# queue_size = 10000
# shuffle_threads = 1
# ratio = 4

# logistic or mse. Use logistic loss (binary) or mean squared error.
loss_type = mse

# Seperated by comma, e.g., file1,file2,.. Regex supported.
train_files = ./data/train_*

# Optional. Seperated by comma. Each weight file corresond to a train file
# and should have the same line number. If not provided, assume weight = 1
# for all examples.
weight_files = ./data/weight_*

# Optional. Seperated by comma. If not provided, skip the validation
# phase. Regex supported.
validation_files = ./data/test_*

[Predict]
predict_files = ./data/test_*
score_path = ./score/
